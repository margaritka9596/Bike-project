{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#кластеризация, (k-mean), one hot encoding, автоматическая настройка параметров xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import *\n",
    "import math as math \n",
    "from numpy.linalg import norm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "train = pd.read_csv('train.csv', delimiter=',', index_col='datetime', parse_dates=True)\n",
    "\n",
    "train['year'] = train.index.year\n",
    "train['month'] = train.index.month\n",
    "train['hour'] = train.index.hour\n",
    "train['day'] = train.index.weekday\n",
    "train['calendar_day'] = train.index.day\n",
    "\n",
    "season = train['month']\n",
    "season = season.apply(lambda s: 4 if int(s) == 1 or int(s) == 2 else (int(s) - 3) // 3 + 1)   \n",
    "train = train.drop('season', axis = 1)\n",
    "train.insert(5, 'season', season)\n",
    "\n",
    "hour = train['hour']\n",
    "mainHour = np.arange(hour.shape[0])\n",
    "mainHour = [1 if (hour[i] == 7) or (hour[i] == 8) or (hour[i] == 17) or (hour[i] == 18) else 0 for i in range(hour.shape[0])]\n",
    "train['mainHour'] = mainHour\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "test = pd.read_csv('test.csv', delimiter=',', index_col='datetime', parse_dates=True)\n",
    "\n",
    "test['year'] = test.index.year\n",
    "test['month'] = test.index.month\n",
    "test['hour'] = test.index.hour\n",
    "test['day'] = test.index.weekday\n",
    "test['calendar_day'] = test.index.day\n",
    "\n",
    "season = test['month']\n",
    "season = season.apply(lambda s: 4 if int(s) == 1 or int(s) == 2 else (int(s) - 3) // 3 + 1)   \n",
    "test = test.drop('season', axis = 1)\n",
    "test.insert(5, 'season', season)\n",
    "\n",
    "hour = test['hour']\n",
    "mainHour = np.arange(hour.shape[0])\n",
    "mainHour = [1 if (hour[i] == 7) or (hour[i] == 8) or (hour[i] == 17) or (hour[i] == 18) else 0 for i in range(hour.shape[0])]\n",
    "test['mainHour'] = mainHour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ONE_hot_encoding \n",
    "#for hours\n",
    "hour_hot = pd.get_dummies(train['hour'], prefix='hour_hot')\n",
    "train = train.join(hour_hot)\n",
    "hour_hot_test = pd.get_dummies(test['hour'], prefix='hour_hot')\n",
    "test = test.join(hour_hot_test)\n",
    "#for weather\n",
    "weather_hot = pd.get_dummies(train['weather'], prefix='weather_hot')\n",
    "train = train.join(weather_hot)\n",
    "weather_hot_test = pd.get_dummies(test['weather'], prefix='weather_hot')\n",
    "test = test.join(weather_hot_test)\n",
    "#for season\n",
    "season_hot = pd.get_dummies(train['season'], prefix='season_hot')\n",
    "train = train.join(season_hot)\n",
    "season_hot_test = pd.get_dummies(test['season'], prefix='season_hot')\n",
    "test = test.join(season_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['hour2'] = (train['hour'])*2\n",
    "test['hour2'] = (test['hour'])*2\n",
    "\n",
    "train['dif1'] = (train['windspeed'] - train['atemp'])**2\n",
    "test['dif1'] = (test['windspeed'] - test['atemp'])**2\n",
    "\n",
    "# train['hum_div_seas'] = (train['humidity']/(train['day']))*2\n",
    "# test['hum_div_seas'] = (test['humidity']/(test['day']))*2\n",
    "\n",
    "# train['hum_div_seas'] = (train['temp']/(train['humidity']))*2\n",
    "# test['hum_div_seas'] = (test['temp']/(test['humidity']))*2\n",
    "\n",
    "\n",
    "\n",
    "#_______________________________________________________________________________________________________________________________\n",
    "#562\n",
    "# param = 5\n",
    "\n",
    "# train_no_count = train.drop(['count', 'casual', 'registered'], axis = 1)\n",
    "# ten_per_train = train_no_count[0:1000]\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(ten_per_train)\n",
    "\n",
    "# labels = kmeans.predict(train_no_count)\n",
    "# train['labels'] = labels\n",
    "\n",
    "# labels = kmeans.predict(test)\n",
    "# test['labels'] = labels\n",
    "\n",
    "# #for cluster labels \n",
    "# labels_hot = pd.get_dummies(train['labels'], prefix='labels_hot')\n",
    "# train = train.join(labels_hot)\n",
    "\n",
    "# labels_hot_test = pd.get_dummies(test['labels'], prefix='labels_hot')\n",
    "# test = test.join(labels_hot_test)\n",
    "\n",
    "X = train.drop(['mainHour','casual', 'registered', 'count'], axis = 1)\n",
    "Xr = train.drop(['casual', 'registered', 'count'], axis = 1)\n",
    "X_test = test.drop(['mainHour'], axis = 1)\n",
    "Xr_test = test\n",
    "\n",
    "# _______________________________________________________________________________________________________________________________\n",
    "\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(X)\n",
    "# X['labels'] = kmeans.labels_\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(Xr)\n",
    "# Xr['labels'] = kmeans.labels_\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(X_test)\n",
    "# X_test['labels'] = kmeans.labels_\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(Xr_test)\n",
    "# Xr_test['labels'] = kmeans.labels_\n",
    "\n",
    "#564\n",
    "# ten_per_X = X[0:1000]\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(ten_per_X)\n",
    "# labels = kmeans.predict(X)\n",
    "# X['labels'] = labels\n",
    "\n",
    "# ten_per_Xr = Xr[0:1000]\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(ten_per_Xr)\n",
    "# labels = kmeans.predict(Xr)\n",
    "# Xr['labels'] = labels\n",
    "\n",
    "# ten_per_X_test = X_test[0:1000]\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(ten_per_X)\n",
    "# labels = kmeans.predict(X_test)\n",
    "# X_test['labels'] = labels\n",
    "\n",
    "# ten_per_Xr_test = Xr_test[0:1000]\n",
    "# kmeans = cluster.KMeans(n_clusters=param, random_state=0).fit(ten_per_Xr)\n",
    "# labels = kmeans.predict(Xr_test)\n",
    "# Xr_test['labels'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxDepth = 3\n",
    "# nEstimators = 700\n",
    "# nEstimators = 900\n",
    "nEstimators = 1200\n",
    "subSample = 0.9\n",
    "\n",
    "y = np.log(train['casual'] + 1)\n",
    "xgb_model = xgb.XGBRegressor(max_depth = maxDepth, n_estimators = nEstimators, subsample = subSample, nthread = 10).fit(X,y)\n",
    "# xgb_model = calibration.CalibratedClassifierCV(xgb_model, method='sigmoid', cv=3).fit(X,y)\n",
    "predictions1 = np.exp(xgb_model.predict(X)) - 1\n",
    "\n",
    "# print(predictions1)\n",
    "# aucXGBTrain = metrics.roc_auc_score(y, predictions1)\n",
    "# print('XGBoost:       {:6.4}'.format(aucXGBTrain))\n",
    "#-----------------------------------\n",
    "y = np.log(train['registered'] + 1)\n",
    "xgb_model = xgb.XGBRegressor(max_depth = maxDepth, n_estimators = nEstimators, subsample = subSample, nthread = 10).fit(Xr,y)\n",
    "# xgb_model = calibration.CalibratedClassifierCV(xgb_model, method='sigmoid', cv=3).fit(X,y)\n",
    "predictions2 = np.exp(xgb_model.predict(Xr)) - 1\n",
    "#-----------------------------------\n",
    "y = train['count']\n",
    "predictions = predictions1 + predictions2\n",
    "predictions = np.round(predictions)\n",
    "\n",
    "print(min(abs(predictions - y)))\n",
    "print(math.sqrt(1 / len(y) * sum((np.log(predictions + 1) - np.log(y + 1))**2)))\n",
    "print(max(abs(predictions - y)))\n",
    "print(len([elem for elem in (abs(predictions - y) / y) if elem < 0.1]), train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.log(train['casual'] + 1)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(max_depth = maxDepth, n_estimators = nEstimators, subsample = subSample, nthread = 8).fit(X,y)\n",
    "predictions1 = np.exp(xgb_model.predict(X_test)) - 1\n",
    "#--------------------------\n",
    "y = np.log(train['registered'] + 1)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(max_depth = maxDepth, n_estimators = nEstimators, subsample = subSample, nthread = 8).fit(Xr,y)\n",
    "predictions2 = np.exp(xgb_model.predict(Xr_test)) - 1\n",
    "#--------------------------\n",
    "predictions = predictions1 + predictions2\n",
    "predictions = np.round(predictions)\n",
    "predictions = [0 if predictions[i] < 0.01 else predictions[i] for i in range(predictions.shape[0])]\n",
    "\n",
    "test.insert(len(test.columns), 'count', predictions)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newny = pd.DataFrame(test.index)\n",
    "newny.insert(1, 'count', predictions)\n",
    "newny.head(20)\n",
    "\n",
    "newny.to_csv('submission.csv', sep=',', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x1 = train.index\n",
    "x2 = test.index\n",
    "\n",
    "y1 = train['count']\n",
    "y2 = test['count']\n",
    "\n",
    "plt.plot(x1, y1, 'g.', x2, y2, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x1 = train.index\n",
    "# x2 = test.index\n",
    "\n",
    "x1 = train['temp']\n",
    "x2 = test['temp']\n",
    "\n",
    "y1 = train['count']\n",
    "y2 = test['count']\n",
    "\n",
    "plt.plot(x1, y1, 'g*', x2, y2, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = train['humidity']\n",
    "x2 = test['humidity']\n",
    "\n",
    "y1 = train['count']\n",
    "y2 = test['count']\n",
    "\n",
    "plt.plot(x1, y1, 'g*', x2, y2, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = test.index\n",
    "y2 = test['count']\n",
    "\n",
    "plt.plot(x2, y2, 'r.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
